# TensorFood

This demo imports a TensorFlow model that is generated by tf.while_loop
for inference in the browser. The model was pre-converted to TensorFlow.js
format and hosted on Google Cloud, using the steps in
the repo's [README.md](../../README.md).

The following commands will start a web server on `localhost:1234` and open
a browser page with the demo.

The demo allows you to change the conditions of the loop interactively and observe the execution result right in the browser.

```bash
cd demo # If not already in the demo directory.
yarn # Installs dependencies.
yarn control_flow # Starts a web server and opens a page. Also watches for changes.
```

## 1. Train Model

```bash
source config
make tensorboard_kill
make train
make train_tfmobileios
```

This gives us `retrained_graph.pb` and `retrained_labels.txt` files. Note that the last line is for deploying TF Mobile on iOS.

## 2. Serialising Data

Serialise the `GraphDef` ProtoBuf file to give `optimized_graph.pb`:

```bash
make optimise_pb
```

We can further quantise the this file to give `rounded_graph.pb`:

```bash
make quantize_android_pb
```

Alternatively, we can use FlatBuffers on the `GraphDef` to give `optimized_graph.lite`:

```bash
make optimize_fb
```

## 3. Deployment

Either deployable in TensorFlow Mobile (more support, stable) or TensorFlow Lite (new but faster).

### Desktop

```bash
make test
```

### Android: TensorFlow Mobile

```bash
make optimise_pb
make export_tfmobile_to_android
```

### Android: TensorFlow Lite

```bash
make export_tflite_to_android
```

### iOS: TensorFlow Mobile

```bash
make train_tfmobileios
make export_tfmobile_to_ios
```

### iOS: TensorFlow Lite

```bash
make export_tflite_to_ios
```

### Web

1) TensorFlow Serving
2) Web server

